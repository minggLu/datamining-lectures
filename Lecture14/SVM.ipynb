{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.sparse.linalg as linalg\n",
    "import scipy.cluster.hierarchy as hr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.utils as utils\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.svm as svm\n",
    "import sklearn.cross_validation as cross_validation\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from patsy import dmatrices\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with the wine dataset available here:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wine = pd.read_table(\"datasets/wine.data\", sep=',')\n",
    "\n",
    "attributes = ['region',\n",
    "'Alcohol',\n",
    "            'Malic acid',\n",
    "            'Ash',\n",
    "            'Alcalinity of ash',\n",
    "            'Magnesium',\n",
    "            'Total phenols',\n",
    "            'Flavanoids',\n",
    "            'Nonflavanoid phenols',\n",
    "            'Proanthocyanins',\n",
    "            'Color intensity',\n",
    "            'Hue',\n",
    "            'OD280/OD315 of diluted wines',\n",
    "            'Proline']\n",
    "\n",
    "\n",
    "\n",
    "wine.columns = attributes\n",
    "# take 2 attributes and use a two dimensional training dataset\n",
    "X = wine[['Alcohol', 'Malic acid',]].values\n",
    "#            'Ash',\n",
    "#            'Alcalinity of ash',\n",
    "#            'Magnesium',\n",
    "#            'Total phenols',\n",
    "#            'Flavanoids', 'Nonflavanoid phenols','Proanthocyanins','Color intensity',  'Hue', 'OD280/OD315 of diluted wines', 'Proline']].values\n",
    "grape = wine.pop('region')\n",
    "y = grape.values\n",
    "\n",
    "print wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wine.head()\n",
    "print X.shape\n",
    "\n",
    "X, y = utils.shuffle(X, y, random_state=1)\n",
    "print X.shape\n",
    "print y.shape\n",
    "print y\n",
    "\n",
    "train_set_size = 100\n",
    "X_train = X[:train_set_size]  # selects first 100 rows (examples) for train set\n",
    "y_train = y[:train_set_size]\n",
    "X_test = X[train_set_size:]   # selects from row 100 until the last one for test set\n",
    "y_test = y[train_set_size:]\n",
    "print(X_train.shape), y_train.shape\n",
    "print(X_test.shape), y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the SVM library of scikit-learn:  http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_test = svc.predict(X_test)\n",
    "print \"Accuracy of SVM test set:\", svc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the fit of the classifier graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "# Create color maps for 3-class classification problem, as with iris\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "def plot_estimator(estimator, X, y):\n",
    "    \n",
    "    try:\n",
    "        X, y = X.values, y.values\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "    estimator.fit(X, y)\n",
    "    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n",
    "    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "    Z = estimator.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "    plt.axis('tight')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_estimator(svc, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The SVM gets its name from the samples in the dataset from each class that lie closest to the other class. These training samples are called \"support vectors\" because changing their position in p-dimensional space would change the location of the decision boundary.\n",
    "\n",
    "In scikits-learn, the indices of the support vectors for each class can be found in the support_vectors_ attribute of the SVC object. Here is a 2 class problem using only classes 1 and 2 in the wine dataset.\n",
    "\n",
    "The support vectors are circled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract classes 1 and 2\n",
    "X, y = X[np.in1d(y, [1, 2])], y[np.in1d(y, [1, 2])]\n",
    "\n",
    "plot_estimator(svc, X, y)\n",
    "plt.scatter(svc.support_vectors_[:, 0], \n",
    "           svc.support_vectors_[:, 1], \n",
    "           s=120, \n",
    "           facecolors='none', \n",
    "           linewidths=2,\n",
    "           zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "These two classes do not appear to be lineary separable.\n",
    "\n",
    "\n",
    "For non-linearly separable classes we turn into regularization; regularization is tuned via the C parameter. In practice, a large C value means that the number of support vectors is small (less regularization), while a small C implies many support vectors (more regularization). scikit-learn sets a default value of C=1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear', C=1e6)\n",
    "plot_estimator(svc, X, y)\n",
    "plt.scatter(svc.support_vectors_[:, 0], svc.support_vectors_[:, 1], s=80, \n",
    "            facecolors='none', linewidths=2, zorder=10)\n",
    "plt.title('High C values: small number of support vectors')\n",
    "\n",
    "svc = svm.SVC(kernel='linear', C=1e-2)\n",
    "plot_estimator(svc, X, y)\n",
    "plt.scatter(svc.support_vectors_[:, 0], svc.support_vectors_[:, 1], s=80, \n",
    "            facecolors='none', linewidths=2, zorder=10)\n",
    "plt.title('Low C values: high number of support vectors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also choose from a suite of available kernels (linear, poly, rbf, sigmoid, precomputed) or a custom kernel can be passed as a function. Note that the radial basis function (rbf) kernel is just a Gaussian kernel, but with parameter $\\gamma = \\frac{1}{\\sigma^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc_lin = svm.SVC(kernel='linear')\n",
    "plot_estimator(svc_lin, X, y)\n",
    "plt.scatter(svc_lin.support_vectors_[:, 0], svc_lin.support_vectors_[:, 1], \n",
    "            s=80, facecolors='none', linewidths=2, zorder=10)\n",
    "plt.title('Linear kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#svc_poly = svm.SVC(kernel='poly', degree=3)\n",
    "#plot_estimator(svc_poly, X, y)\n",
    "#plt.scatter(svc_poly.support_vectors_[:, 0], svc_poly.support_vectors_[:, 1], \n",
    "#           s=80, facecolors='none', linewidths=2, zorder=10)\n",
    "#plt.title('Polynomial kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#svc_rbf = svm.SVC(kernel='rbf', gamma=1e-2)\n",
    "#plot_estimator(svc_rbf, X, y)\n",
    "#plt.scatter(svc_rbf.support_vectors_[:, 0], svc_rbf.support_vectors_[:, 1], \n",
    "#           s=80, facecolors='none', linewidths=2, zorder=10)\n",
    "#plt.title('RBF kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "        wine.values, grape.values, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = svm.SVC(kernel='linear', C=1)\n",
    "f.fit(X_train, y_train)\n",
    "f.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mean accuracy\n",
    "scores = cross_validation.cross_val_score(f, wine.values, grape.values, cv=5)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#precision\n",
    "cross_validation.cross_val_score(f, wine.values, grape.values, cv=5, scoring='precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features. We could\n",
    "                      # avoid this ugly slicing by using a two-dim dataset\n",
    "y = iris.target\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# we create an instance of SVM and fit out data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "C = 1.0  # SVM regularization parameter\n",
    "svc = svm.SVC(kernel='linear', C=C).fit(X, y)\n",
    "rbf_svc = svm.SVC(kernel='rbf', gamma=0.7, C=C).fit(X, y)\n",
    "poly_svc = svm.SVC(kernel='poly', degree=3, C=C).fit(X, y)\n",
    "lin_svc = svm.LinearSVC(C=C).fit(X, y)\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# title for the plots\n",
    "titles = ['SVC with linear kernel',\n",
    "          'LinearSVC (linear kernel)',\n",
    "          'SVC with RBF kernel', 'SVC with poly kernel']\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "for i, clf in enumerate((svc, lin_svc, rbf_svc, poly_svc)):\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(titles[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code for setting the style of the notebook\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
